# ğŸš¢ Reinforcement Learning: Q-Learning vs Deep Q-Learning in Grid Navigation

Dieses Projekt untersucht und vergleicht tabellenbasiertes Q-Learning mit Deep Q-Learning (DQN) zur Navigation autonomer Agenten in simulierten Gitterumgebungen. Ziel ist eine reproduzierbare Evaluation beider Verfahren unter einheitlichen Rahmenbedingungen.

## ğŸ“ Projektstruktur

```
ship-navigation-ql-dqn/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ q_learning/          # Q-Learning-Training, Evaluation, Visualisierung
â”‚   â”œâ”€â”€ dqn/                 # DQN-Training, Evaluation, Visualisierung
â”‚   â”œâ”€â”€ comparison/          # Algorithmusvergleich & Visualisierungen
â”‚   â””â”€â”€ shared/              # Konfigurationen, Umgebungen, utils
â”œâ”€â”€ docs/                    # Dokumentation (MkDocs)
â”œâ”€â”€ exports/                 # Ausgabedateien (PDFs, CSVs, Plots)
â””â”€â”€ README.md                # ProjektÃ¼bersicht
```

## âš™ï¸ Setup

1. Repository klonen  
2. Virtuelle Umgebung erstellen und aktivieren  
3. AbhÃ¤ngigkeiten installieren

```bash
git clone https://github.com/DeinUser/ship-navigation-ql-dqn.git
cd ship-navigation-ql-dqn
python -m venv venv
venv\Scripts\activate     # Windows
source venv/bin/activate    # Linux/Mac
pip install -r requirements.txt
```

## ğŸ§  Trainingssteuerung

### Q-Learning

```bash
cd src/q_learning
python train_all_scenarios.py
```

### Deep Q-Learning

```bash
cd src/dqn
python train_all_scenarios.py --episodes 500 --runs 3
```

### Vergleichsvisualisierung
## ğŸ“Š Vergleichsvisualisierung

Es stehen drei Varianten fÃ¼r den visuellen Vergleich der Algorithmen zur VerfÃ¼gung:

1. **2x3-Visualisierung** (`compare_algorithms_2x3.py`)  
   â†’ FÃ¼hrt die Evaluation durch und speichert die CSV-Datei (`algorithm_comparison_2x3.csv`)

2. **2x2 V1** (`compare_algorithms_2x2_v1.py`)  
   â†’ Wissenschaftliches Grid-Layout mit Erfolgsraten, Belohnung, Schritten und Scatterplot  
   **Nutzt die CSV aus 2x3 als Grundlage.**

3. **2x2 V2** (`compare_algorithms_2x2_v2.py`)  
   â†’ Fokus auf Single-Agent-Darstellung mit Heatmap  
   **Nutzt ebenfalls die CSV aus 2x3 als Grundlage.**

â¡ï¸ **Wichtig:** Die 2x3-Variante muss vor den anderen beiden ausgefÃ¼hrt werden.


```bash
cd src/comparison
python compare_algorithms_2x2_v1.py
```

## ğŸŒ Szenarien

Es werden fÃ¼nf Varianten unterschieden:
- `static` â€“ feste Start-/Ziel-/Hindernispositionen
- `random_start` â€“ zufÃ¤lliger Start
- `random_goal` â€“ zufÃ¤lliges Ziel
- `random_obstacles` â€“ zufÃ¤llige Hindernisse
- `container` â€“ Aufgaben mit Pickup & Dropoff

## ğŸ“Š Ergebnisse

Ergebnisse und Visualisierungen (Lernkurven, Erfolgsraten, Vergleichsplots) werden automatisch im jeweiligen `exports/`-Verzeichnis gespeichert. Q-Tabellen und Modellgewichte werden szenariobezogen abgelegt.

## ğŸ“š Dokumentation

Die technische und inhaltliche Dokumentation ist mit MkDocs aufbereitet:

```bash
mkdocs serve
```

â†’ erreichbar unter [http://localhost:8000](http://localhost:8000)

