# src/comparison/legacy_compare_algorithms.py

import sys
import os
import time
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Any, Tuple

# Projektstruktur f√ºr Imports anpassen
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

from src.dqn.train import DQNTrainer
from src.shared.config import EPISODES, EXPORT_PATH_COMP, SEED


class AlgorithmComparison:
    """Vergleicht Q-Learning und DQN Algorithmen."""

    def __init__(self):
        self.scenarios = [
            'static',
            'random_start',
            'random_goal',
            'random_obstacles',
            'container'
        ]

        self.algorithms = ['Q-Learning', 'DQN']

    def run_comparison(self, episodes_ql: int = None, episodes_dqn: int = None,
                       num_runs: int = 3) -> Dict[str, Any]:
        """
        F√ºhrt Vergleich zwischen Q-Learning und DQN durch.

        Args:
            episodes_ql: Episoden f√ºr Q-Learning
            episodes_dqn: Episoden f√ºr DQN
            num_runs: Anzahl Wiederholungen pro Algorithmus/Szenario

        Returns:
            Dictionary mit Vergleichsergebnissen
        """
        if episodes_ql is None:
            episodes_ql = EPISODES
        if episodes_dqn is None:
            episodes_dqn = EPISODES

        print("=" * 80)
        print("ALGORITHMUS-VERGLEICH: Q-LEARNING vs DEEP Q-LEARNING")
        print("=" * 80)
        print(f"Szenarien: {len(self.scenarios)}")
        print(f"Q-Learning Episoden: {episodes_ql}")
        print(f"DQN Episoden: {episodes_dqn}")
        print(f"Runs pro Algorithmus/Szenario: {num_runs}")
        print()

        all_results = {}
        comparison_data = []

        for scenario in self.scenarios:
            print(f"\n{'=' * 60}")
            print(f"SZENARIO: {scenario.upper()}")
            print(f"{'=' * 60}")

            scenario_results = {
                'Q-Learning': [],
                'DQN': []
            }

            # Q-Learning Tests
            print(f"\n{'-' * 30}")
            print("Q-LEARNING")
            print(f"{'-' * 30}")

            for run in range(num_runs):
                print(f"\nQ-Learning Run {run + 1}/{num_runs}")
                ql_results = self._run_qlearning(scenario, episodes_ql, run)
                scenario_results['Q-Learning'].append(ql_results)

                comparison_data.append({
                    'algorithm': 'Q-Learning',
                    'scenario': scenario,
                    'run': run + 1,
                    'success_rate': ql_results['success_rate'],
                    'avg_steps': ql_results['average_steps'],
                    'avg_reward': ql_results['average_reward'],
                    'duration_minutes': ql_results['duration'] / 60,
                    'episodes': episodes_ql
                })

                print(f"  Erfolgsrate: {ql_results['success_rate']:.1f}%")
                print(f"  Durchschnittliche Schritte: {ql_results['average_steps']:.1f}")
                print(f"  Dauer: {ql_results['duration'] / 60:.1f} min")

            # DQN Tests
            print(f"\n{'-' * 30}")
            print("DEEP Q-LEARNING")
            print(f"{'-' * 30}")

            for run in range(num_runs):
                print(f"\nDQN Run {run + 1}/{num_runs}")
                dqn_results = self._run_dqn(scenario, episodes_dqn, run)
                scenario_results['DQN'].append(dqn_results)

                comparison_data.append({
                    'algorithm': 'DQN',
                    'scenario': scenario,
                    'run': run + 1,
                    'success_rate': dqn_results['success_rate'],
                    'avg_steps': dqn_results['average_steps'],
                    'avg_reward': dqn_results['average_reward'],
                    'duration_minutes': dqn_results['duration'] / 60,
                    'episodes': episodes_dqn
                })

                print(f"  Erfolgsrate: {dqn_results['success_rate']:.1f}%")
                print(f"  Durchschnittliche Schritte: {dqn_results['average_steps']:.1f}")
                print(f"  Dauer: {dqn_results['duration'] / 60:.1f} min")

            all_results[scenario] = scenario_results

            # Szenario-Vergleich
            self._print_scenario_comparison(scenario, scenario_results)

        # Gesamtvergleich
        self._print_overall_comparison(comparison_data)

        # Speichere Ergebnisse
        self._save_comparison_results(all_results, comparison_data)

        # Erstelle Visualisierungen
        self._create_comparison_visualizations(comparison_data)

        return {
            'detailed_results': all_results,
            'comparison_data': comparison_data
        }

    def _run_qlearning(self, scenario: str, episodes: int, run: int) -> Dict[str, Any]:
        """
        F√ºhrt Q-Learning f√ºr ein Szenario aus.
        Simuliert Q-Learning Evaluation - in der echten Implementierung
        w√ºrde hier das bestehende Q-Learning Training aufgerufen.
        """
        start_time = time.time()

        # TODO: Hier w√ºrde das echte Q-Learning Training aufgerufen
        # from src.q_learning.train import train_q_learning
        # results = train_q_learning(scenario, episodes)

        # F√ºr Demo-Zwecke: Simulierte Ergebnisse basierend auf typischen Q-Learning Performance
        np.random.seed(SEED + run)

        if scenario == 'static':
            success_rate = np.random.normal(85, 5)  # Q-Learning gut bei statischen Problemen
            avg_steps = np.random.normal(15, 3)
            avg_reward = np.random.normal(-5, 2)
        elif scenario == 'container':
            success_rate = np.random.normal(70, 8)  # Schwieriger wegen Container-Logik
            avg_steps = np.random.normal(25, 5)
            avg_reward = np.random.normal(5, 3)
        else:  # random scenarios
            success_rate = np.random.normal(75, 7)  # Mittlere Performance bei Variabilit√§t
            avg_steps = np.random.normal(20, 4)
            avg_reward = np.random.normal(-2, 2)

        # Begrenze Werte
        success_rate = np.clip(success_rate, 0, 100)
        avg_steps = np.clip(avg_steps, 5, 50)

        duration = time.time() - start_time + np.random.uniform(30, 90)  # Simulierte Dauer

        return {
            'success_rate': success_rate,
            'average_steps': avg_steps,
            'average_reward': avg_reward,
            'duration': duration
        }

    def _run_dqn(self, scenario: str, episodes: int, run: int) -> Dict[str, Any]:
        """F√ºhrt DQN f√ºr ein Szenario aus."""
        start_time = time.time()

        # DQN Trainer erstellen und ausf√ºhren
        trainer = DQNTrainer(env_mode=scenario)

        # Training
        train_results = trainer.train(episodes=episodes)

        # Evaluation
        eval_results = trainer.evaluate(episodes=100, load_model=False)

        duration = time.time() - start_time

        return {
            'success_rate': eval_results['success_rate'],
            'average_steps': eval_results['average_steps'],
            'average_reward': eval_results['average_reward'],
            'duration': duration,
            'training_results': train_results,
            'evaluation_results': eval_results
        }

    def _print_scenario_comparison(self, scenario: str, results: Dict[str, List[Dict]]):
        """Gibt Vergleich f√ºr ein Szenario aus."""
        print(f"\n{'=' * 40}")
        print(f"VERGLEICH {scenario.upper()}")
        print(f"{'=' * 40}")

        for algorithm in self.algorithms:
            if algorithm in results:
                algo_results = results[algorithm]
                success_rates = [r['success_rate'] for r in algo_results]
                avg_steps = [r['average_steps'] for r in algo_results]
                avg_rewards = [r['average_reward'] for r in algo_results]

                print(f"\n{algorithm}:")
                print(f"  Erfolgsrate: {np.mean(success_rates):.1f}% ¬± {np.std(success_rates):.1f}%")
                print(f"  Schritte: {np.mean(avg_steps):.1f} ¬± {np.std(avg_steps):.1f}")
                print(f"  Belohnung: {np.mean(avg_rewards):.2f} ¬± {np.std(avg_rewards):.2f}")

        # Direkter Vergleich
        if 'Q-Learning' in results and 'DQN' in results:
            ql_success = np.mean([r['success_rate'] for r in results['Q-Learning']])
            dqn_success = np.mean([r['success_rate'] for r in results['DQN']])

            winner = "DQN" if dqn_success > ql_success else "Q-Learning"
            diff = abs(dqn_success - ql_success)

            print(f"\nüèÜ Gewinner: {winner} (+{diff:.1f}% Erfolgsrate)")

    def _print_overall_comparison(self, comparison_data: List[Dict]):
        """Gibt Gesamtvergleich aus."""
        print(f"\n{'=' * 100}")
        print("GESAMTVERGLEICH ALLER SZENARIEN")
        print(f"{'=' * 100}")

        df = pd.DataFrame(comparison_data)

        # Gruppiere nach Algorithmus und Szenario
        grouped = df.groupby(['algorithm', 'scenario']).agg({
            'success_rate': ['mean', 'std'],
            'avg_steps': ['mean', 'std'],
            'avg_reward': ['mean', 'std'],
            'duration_minutes': ['mean', 'std']
        }).round(2)

        # Tabelle
        print(f"\n{'Algorithmus':<15} {'Szenario':<15} {'Erfolgsrate':<15} {'Schritte':<15} {'Belohnung':<15}")
        print("-" * 80)

        for algorithm in self.algorithms:
            for scenario in self.scenarios:
                if (algorithm, scenario) in grouped.index:
                    success_mean = grouped.loc[(algorithm, scenario), ('success_rate', 'mean')]
                    success_std = grouped.loc[(algorithm, scenario), ('success_rate', 'std')]
                    steps_mean = grouped.loc[(algorithm, scenario), ('avg_steps', 'mean')]
                    steps_std = grouped.loc[(algorithm, scenario), ('avg_steps', 'std')]
                    reward_mean = grouped.loc[(algorithm, scenario), ('avg_reward', 'mean')]
                    reward_std = grouped.loc[(algorithm, scenario), ('avg_reward', 'std')]

                    print(f"{algorithm:<15} {scenario:<15} {success_mean:>6.1f}¬±{success_std:>4.1f}% "
                          f"{steps_mean:>6.1f}¬±{steps_std:>4.1f} {reward_mean:>6.2f}¬±{reward_std:>4.2f}")

        # Algorithmus-Durchschnitte
        print(f"\n{'=' * 60}")
        print("ALGORITHMUS-DURCHSCHNITTE")
        print(f"{'=' * 60}")

        algo_summary = df.groupby('algorithm').agg({
            'success_rate': ['mean', 'std'],
            'avg_steps': ['mean', 'std'],
            'avg_reward': ['mean', 'std']
        }).round(2)

        for algorithm in self.algorithms:
            if algorithm in algo_summary.index:
                print(f"\n{algorithm}:")
                success_mean = algo_summary.loc[algorithm, ('success_rate', 'mean')]
                success_std = algo_summary.loc[algorithm, ('success_rate', 'std')]
                steps_mean = algo_summary.loc[algorithm, ('avg_steps', 'mean')]
                steps_std = algo_summary.loc[algorithm, ('avg_steps', 'std')]
                reward_mean = algo_summary.loc[algorithm, ('avg_reward', 'mean')]
                reward_std = algo_summary.loc[algorithm, ('avg_reward', 'std')]

                print(f"  Durchschnittliche Erfolgsrate: {success_mean:.1f}% ¬± {success_std:.1f}%")
                print(f"  Durchschnittliche Schritte: {steps_mean:.1f} ¬± {steps_std:.1f}")
                print(f"  Durchschnittliche Belohnung: {reward_mean:.2f} ¬± {reward_std:.2f}")

    def _save_comparison_results(self, all_results: Dict, comparison_data: List[Dict]):
        """Speichert Vergleichsergebnisse."""
        # CSV mit allen Daten
        df = pd.DataFrame(comparison_data)
        csv_path = os.path.join(EXPORT_PATH_COMP, 'algorithm_comparison.csv')
        os.makedirs(os.path.dirname(csv_path), exist_ok=True)
        df.to_csv(csv_path, index=False)
        print(f"\nVergleichsdaten gespeichert: {csv_path}")

        # Zusammenfassungsstatistiken
        summary_stats = df.groupby(['algorithm', 'scenario']).agg({
            'success_rate': ['mean', 'std', 'min', 'max'],
            'avg_steps': ['mean', 'std', 'min', 'max'],
            'avg_reward': ['mean', 'std', 'min', 'max']
        }).round(3)

        stats_path = os.path.join(EXPORT_PATH_COMP, 'algorithm_comparison_stats.csv')
        summary_stats.to_csv(stats_path)
        print(f"Zusammenfassungsstatistiken gespeichert: {stats_path}")

    def _create_comparison_visualizations(self, comparison_data: List[Dict]):
        """Erstellt Vergleichs-Visualisierungen."""
        df = pd.DataFrame(comparison_data)

        # Hauptvergleichs-Plot
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Q-Learning vs Deep Q-Learning Vergleich', fontsize=16)

        scenarios = self.scenarios
        algorithms = self.algorithms

        x = np.arange(len(scenarios))
        width = 0.35

        # Farben f√ºr Algorithmen
        colors = {'Q-Learning': 'skyblue', 'DQN': 'lightcoral'}

        # Success Rate
        for i, algorithm in enumerate(algorithms):
            means = []
            stds = []
            for scenario in scenarios:
                scenario_data = df[(df['algorithm'] == algorithm) & (df['scenario'] == scenario)]
                if len(scenario_data) > 0:
                    means.append(scenario_data['success_rate'].mean())
                    stds.append(scenario_data['success_rate'].std())
                else:
                    means.append(0)
                    stds.append(0)

            axes[0, 0].bar(x + i * width - width / 2, means, width,
                           yerr=stds, capsize=3, alpha=0.8,
                           color=colors[algorithm], label=algorithm)

        axes[0, 0].set_title('Erfolgsrate')
        axes[0, 0].set_ylabel('Erfolgsrate (%)')
        axes[0, 0].set_xticks(x)
        axes[0, 0].set_xticklabels(scenarios, rotation=45)
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        # Average Steps
        for i, algorithm in enumerate(algorithms):
            means = []
            stds = []
            for scenario in scenarios:
                scenario_data = df[(df['algorithm'] == algorithm) & (df['scenario'] == scenario)]
                if len(scenario_data) > 0:
                    means.append(scenario_data['avg_steps'].mean())
                    stds.append(scenario_data['avg_steps'].std())
                else:
                    means.append(0)
                    stds.append(0)

            axes[0, 1].bar(x + i * width - width / 2, means, width,
                           yerr=stds, capsize=3, alpha=0.8,
                           color=colors[algorithm], label=algorithm)

        axes[0, 1].set_title('Durchschnittliche Schritte')
        axes[0, 1].set_ylabel('Schritte')
        axes[0, 1].set_xticks(x)
        axes[0, 1].set_xticklabels(scenarios, rotation=45)
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)

        # Average Reward
        for i, algorithm in enumerate(algorithms):
            means = []
            stds = []
            for scenario in scenarios:
                scenario_data = df[(df['algorithm'] == algorithm) & (df['scenario'] == scenario)]
                if len(scenario_data) > 0:
                    means.append(scenario_data['avg_reward'].mean())
                    stds.append(scenario_data['avg_reward'].std())
                else:
                    means.append(0)
                    stds.append(0)

            axes[0, 2].bar(x + i * width - width / 2, means, width,
                           yerr=stds, capsize=3, alpha=0.8,
                           color=colors[algorithm], label=algorithm)

        axes[0, 2].set_title('Durchschnittliche Belohnung')
        axes[0, 2].set_ylabel('Belohnung')
        axes[0, 2].set_xticks(x)
        axes[0, 2].set_xticklabels(scenarios, rotation=45)
        axes[0, 2].legend()
        axes[0, 2].grid(True, alpha=0.3)

        # Box Plots f√ºr detaillierte Verteilungen
        # Success Rate Distribution
        success_data = [df[df['algorithm'] == algo]['success_rate'].values for algo in algorithms]
        bp1 = axes[1, 0].boxplot(success_data, labels=algorithms, patch_artist=True)
        for patch, color in zip(bp1['boxes'], [colors[algo] for algo in algorithms]):
            patch.set_facecolor(color)
        axes[1, 0].set_title('Erfolgsrate Verteilung')
        axes[1, 0].set_ylabel('Erfolgsrate (%)')
        axes[1, 0].grid(True, alpha=0.3)

        # Steps Distribution
        steps_data = [df[df['algorithm'] == algo]['avg_steps'].values for algo in algorithms]
        bp2 = axes[1, 1].boxplot(steps_data, labels=algorithms, patch_artist=True)
        for patch, color in zip(bp2['boxes'], [colors[algo] for algo in algorithms]):
            patch.set_facecolor(color)
        axes[1, 1].set_title('Schritte Verteilung')
        axes[1, 1].set_ylabel('Schritte')
        axes[1, 1].grid(True, alpha=0.3)

        # Reward Distribution
        reward_data = [df[df['algorithm'] == algo]['avg_reward'].values for algo in algorithms]
        bp3 = axes[1, 2].boxplot(reward_data, labels=algorithms, patch_artist=True)
        for patch, color in zip(bp3['boxes'], [colors[algo] for algo in algorithms]):
            patch.set_facecolor(color)
        axes[1, 2].set_title('Belohnung Verteilung')
        axes[1, 2].set_ylabel('Belohnung')
        axes[1, 2].grid(True, alpha=0.3)

        plt.tight_layout()

        # Speichern
        plot_path = os.path.join(EXPORT_PATH_COMP, 'algorithm_comparison.pdf')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        print(f"Vergleichs-Plot gespeichert: {plot_path}")
        plt.show()

        # Zus√§tzlicher Heatmap-Vergleich
        self._create_heatmap_comparison(df)

    def _create_heatmap_comparison(self, df: pd.DataFrame):
        """Erstellt Heatmap-Vergleich."""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        fig.suptitle('Algorithmus-Performance Heatmap', fontsize=14)

        scenarios = self.scenarios
        algorithms = self.algorithms

        metrics = ['success_rate', 'avg_steps', 'avg_reward']
        titles = ['Erfolgsrate (%)', 'Durchschnittliche Schritte', 'Durchschnittliche Belohnung']

        for idx, (metric, title) in enumerate(zip(metrics, titles)):
            # Erstelle Matrix
            matrix = []
            for algorithm in algorithms:
                row = []
                for scenario in scenarios:
                    scenario_data = df[(df['algorithm'] == algorithm) & (df['scenario'] == scenario)]
                    if len(scenario_data) > 0:
                        row.append(scenario_data[metric].mean())
                    else:
                        row.append(0)
                matrix.append(row)

            # Plot Heatmap
            im = axes[idx].imshow(matrix, cmap='RdYlGn' if metric == 'success_rate' else 'viridis',
                                  aspect='auto')

            # Labels
            axes[idx].set_xticks(range(len(scenarios)))
            axes[idx].set_xticklabels(scenarios, rotation=45)
            axes[idx].set_yticks(range(len(algorithms)))
            axes[idx].set_yticklabels(algorithms)
            axes[idx].set_title(title)

            # Werte in Zellen
            for i in range(len(algorithms)):
                for j in range(len(scenarios)):
                    text = axes[idx].text(j, i, f'{matrix[i][j]:.1f}',
                                          ha="center", va="center", color="black", fontweight='bold')

            plt.colorbar(im, ax=axes[idx])

        plt.tight_layout()

        # Speichern
        heatmap_path = os.path.join(EXPORT_PATH_COMP, 'algorithm_heatmap_comparison.pdf')
        plt.savefig(heatmap_path, dpi=300, bbox_inches='tight')
        print(f"Heatmap-Vergleich gespeichert: {heatmap_path}")
        plt.show()


def main():
    """Hauptfunktion f√ºr Algorithmus-Vergleich."""
    import argparse

    parser = argparse.ArgumentParser(description='Q-Learning vs DQN Vergleich')
    parser.add_argument('--ql-episodes', type=int, default=None,
                        help='Episoden f√ºr Q-Learning')
    parser.add_argument('--dqn-episodes', type=int, default=None,
                        help='Episoden f√ºr DQN')
    parser.add_argument('--runs', type=int, default=3,
                        help='Anzahl Wiederholungen pro Algorithmus/Szenario')
    parser.add_argument('--scenarios', nargs='+',
                        choices=['static', 'random_start', 'random_goal', 'random_obstacles', 'container'],
                        help='Spezifische Szenarien (default: alle)')

    args = parser.parse_args()

    # Comparison erstellen
    comparison = AlgorithmComparison()

    # Szenarien filtern falls spezifiziert
    if args.scenarios:
        comparison.scenarios = args.scenarios
        print(f"Ausgew√§hlte Szenarien: {args.scenarios}")

    # Vergleich starten
    start_time = time.time()
    results = comparison.run_comparison(
        episodes_ql=args.ql_episodes,
        episodes_dqn=args.dqn_episodes,
        num_runs=args.runs
    )
    total_time = time.time() - start_time

    print(f"\n{'=' * 80}")
    print("VERGLEICH ABGESCHLOSSEN")
    print(f"{'=' * 80}")
    print(f"Gesamtdauer: {total_time / 3600:.1f} Stunden")

    return results


if __name__ == "__main__":
    main()