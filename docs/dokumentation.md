# Dokumentation und Entwicklung

## Lokale Dokumentation

```bash
# Entwicklungsmodus starten
mkdocs serve
# Verf√ºgbar unter: http://127.0.0.1:8000

# Statische HTML-Dateien generieren  
mkdocs build

# Dokumentation mit Auto-Reload
mkdocs serve --dev-addr=127.0.0.1:8001
```

## Dokumentationsstruktur

```
docs/
‚îú‚îÄ‚îÄ index.md              # Projekt√ºbersicht und Algorithmus-Vergleich
‚îú‚îÄ‚îÄ setup.md              # Installation f√ºr Q-Learning und DQN  
‚îú‚îÄ‚îÄ funktionsweise.md     # Q-Learning und DQN Algorithmus-Details
‚îú‚îÄ‚îÄ training.md           # Training beider Algorithmen und Vergleiche
‚îú‚îÄ‚îÄ visualisierung.md     # Analyse-Tools f√ºr beide Algorithmen
‚îî‚îÄ‚îÄ dokumentation.md      # Diese Entwicklungsdokumentation
```

### Inhaltliche Abdeckung

| Datei | Fokus | Zielgruppe | Algorithmen |
|-------|-------|------------|-------------|
| **index.md** | Projekt√ºbersicht, Vergleich, Architektur | Alle Nutzer | Q-Learning + DQN |
| **setup.md** | Installation, Grundlagen, Troubleshooting | Neue Nutzer | Beide Algorithmen |
| **funktionsweise.md** | Algorithmus-Details, Module, Vergleich | Entwickler, Forscher | Q-Learning + DQN |
| **training.md** | Parameter, Szenarien, Best Practices | Praktische Anwendung | Beide + Vergleich |
| **visualisierung.md** | Plots, Exports, Interpretation | Analyse und Ergebnisse | Q-Learning + DQN |
| **dokumentation.md** | MkDocs, Entwicklung, Wartung | Entwickler | Projekt-Wartung |

## Projektarchitektur-Dokumentation

### Code-Struktur
```
ship-navigation-ql-dqn/
‚îú‚îÄ‚îÄ src/                           # Hauptcode
‚îÇ   ‚îú‚îÄ‚îÄ q_learning/                # Q-Learning Implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ *.py                   # Q-Learning Ausf√ºhrbare Scripts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exports/               # Q-Learning spezifische Exports
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/                 # Q-Learning Wiederverwendbare Module
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py       # Q-Learning Package mit Exports
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ common.py         # Q-Learning Basis-Hilfsfunktionen
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ environment.py    # Q-Learning Umgebungs-Management
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ qlearning.py      # Q-Learning Algorithmus
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ evaluation.py     # Q-Learning Bewertungslogik
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ position.py       # Q-Learning Position/State Konvertierungen
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ visualization.py  # Q-Learning Plotting-Funktionen
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ reporting.py      # Q-Learning Ausgabe-Funktionen
‚îÇ   ‚îú‚îÄ‚îÄ dqn/                       # Deep Q-Learning Implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deep_q_agent.py       # DQN Agent mit Neural Networks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py              # DQN Training Scripts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_all_scenarios.py # DQN Batch Processing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ exports/              # DQN spezifische Exports
‚îÇ   ‚îú‚îÄ‚îÄ comparison/                # Algorithmus-Vergleich
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ compare_algorithms.py # Q-Learning vs DQN Vergleich
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ exports/              # Vergleichs-spezifische Exports
‚îÇ   ‚îú‚îÄ‚îÄ shared/                    # Gemeinsame Komponenten
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py             # Zentrale Konfiguration (beide Algorithmen)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ envs/                 # Gemeinsame Umgebungs-Implementierungen
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py       # Shared Envs Package-Initialisierung
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ grid_environment.py # Standard Grid-Umgebung
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ container_environment.py # Container Pickup/Dropoff
‚îÇ   ‚îî‚îÄ‚îÄ experiments/               # Wissenschaftliche Experimente
‚îú‚îÄ‚îÄ docs/                          # MkDocs Dokumentation
‚îú‚îÄ‚îÄ exports/                       # Legacy/Gemeinsame Visualisierungen
‚îú‚îÄ‚îÄ mkdocs.yml                     # Dokumentations-Konfiguration
‚îú‚îÄ‚îÄ requirements.txt               # Python-Abh√§ngigkeiten (beide Algorithmen)
‚îî‚îÄ‚îÄ README.md                      # Projekt-Hauptdokumentation
```

### Modulare Multi-Algorithmus Architektur

Das System folgt modernen Software-Engineering-Prinzipien mit Algorithmus-Trennung:

- **DRY-Prinzip**: Keine Code-Duplikation durch Shared-Module
- **Single Responsibility**: Jedes Modul hat eine klare Aufgabe (Q-Learning oder DQN)
- **Clean Imports**: Strukturierte Package-Hierarchie mit Algorithmus-Trennung
- **Algorithmus-Abstraktion**: Q-Learning und DQN nutzen gemeinsame Interfaces
- **Wiederverwendbarkeit**: Shared Utils k√∂nnen in anderen Multi-Algorithmus RL-Projekten genutzt werden

### Algorithmus-spezifische Verantwortlichkeiten

=== "Q-Learning Module"
    ```python
    q_learning/
    ‚îú‚îÄ‚îÄ utils/qlearning.py      # Q-Tabellen Algorithmus
    ‚îú‚îÄ‚îÄ utils/evaluation.py     # Q-Tabellen spezifische Evaluation
    ‚îú‚îÄ‚îÄ utils/visualization.py  # Q-Learning spezifische Plots
    ‚îî‚îÄ‚îÄ exports/               # Q-Tabellen, Q-Learning Plots
    ```

=== "DQN Module"
    ```python
    dqn/
    ‚îú‚îÄ‚îÄ deep_q_agent.py        # Neural Network basierter Agent
    ‚îú‚îÄ‚îÄ train.py              # DQN-spezifisches Training
    ‚îî‚îÄ‚îÄ exports/              # Neural Network Models, DQN Plots
    ```

=== "Shared Module"
    ```python
    shared/
    ‚îú‚îÄ‚îÄ config.py             # Parameter f√ºr beide Algorithmen
    ‚îî‚îÄ‚îÄ envs/                 # Gymnasium Environments f√ºr beide
    ```

=== "Comparison Module"
    ```python
    comparison/
    ‚îú‚îÄ‚îÄ compare_algorithms.py  # Q-Learning vs DQN direkter Vergleich
    ‚îî‚îÄ‚îÄ exports/              # Algorithmus-Vergleichsplots
    ```

## GitHub Pages Deployment

```bash
# Automatisches Deployment zu GitHub Pages
mkdocs gh-deploy

# Mit spezifischem Branch
mkdocs gh-deploy --remote-branch gh-pages

# Mit benutzerdefinierter Commit-Message
mkdocs gh-deploy -m "Update documentation f√ºr Q-Learning + DQN v2.0"
```

### Deployment-Konfiguration
```yaml
# mkdocs.yml
site_url: https://Ul012.github.io/FOM-rl-shipnav-ql-dql/
repo_url: https://github.com/Ul012/FOM-rl-shipnav-ql-dql
repo_name: FOM-rl-shipnav-ql-dql
```

## Toolchain-Details

### Abh√§ngigkeiten
```bash
# Basis-Installation f√ºr Dokumentation
pip install mkdocs>=1.5.0
pip install mkdocs-material>=9.0.0

# Erweiterte Features (optional)
pip install mkdocs-mermaid2-plugin    # Algorithmus-Diagramme
pip install mkdocs-pdf-export-plugin  # PDF-Export der Dokumentation
pip install mkdocs-git-revision-date-plugin  # Git-Integration
pip install mkdocs-tabbed-plugin      # Tabbed Content f√ºr Algorithmus-Vergleiche
```

### Erweiterte mkdocs.yml Konfiguration
```yaml
site_name: RL Ship Navigation - Q-Learning vs Deep Q-Learning
site_description: Vergleich zwischen Q-Learning und Deep Q-Learning f√ºr autonome Schiffsnavigation
site_author: Ship Navigation RL Project

theme:
  name: material
  palette:
    - scheme: default
      primary: blue
      accent: cyan
      toggle:
        icon: material/brightness-7
        name: Switch to dark mode
    - scheme: slate
      primary: blue
      accent: cyan
      toggle:
        icon: material/brightness-4
        name: Switch to light mode
  features:
    - navigation.tabs
    - navigation.sections
    - navigation.top
    - toc.integrate
    - search.highlight
    - content.code.copy
    - content.code.annotate

nav:
  - üè† Startseite: index.md
  - ‚öôÔ∏è Setup: setup.md
  - üß† Funktionsweise: funktionsweise.md
  - üéØ Training: training.md
  - üìä Visualisierung: visualisierung.md
  - üìö Entwicklung: dokumentation.md

markdown_extensions:
  - admonition
  - codehilite
  - toc:
      permalink: true
  - pymdownx.emoji:
      emoji_index: !!python/name:materialx.emoji.twemoji
      emoji_generator: !!python/name:materialx.emoji.to_svg
  - pymdownx.tabbed:
      alternate_style: true  # F√ºr Q-Learning vs DQN Tabs
  - pymdownx.superfences    # F√ºr Code-Bl√∂cke beider Algorithmen

plugins:
  - search
  - git-revision-date-localized:
      type: date

extra:
  social:
    - icon: fontawesome/brands/github
      link: https://github.com/Ul012/FOM-rl-shipnav-ql-dql
```

## Entwicklungsworkflow

### Dokumentation aktualisieren
1. **Lokale Bearbeitung**: Markdown-Dateien in `docs/` editieren f√ºr beide Algorithmen
2. **Preview**: `mkdocs serve` f√ºr Live-Vorschau mit Q-Learning + DQN Inhalten
3. **Testing**: Alle Links und Code-Beispiele beider Algorithmen pr√ºfen
4. **Deployment**: `mkdocs gh-deploy` f√ºr Ver√∂ffentlichung

### Multi-Algorithmus Code-Dokumentation Standards
```python
# Q-Learning Funktions-Kommentare
# Kurze Q-Learning spezifische Beschreibung √ºber der Funktion
def q_learning_function(param1, param2):
    # Q-Learning Implementation details
    pass

# DQN Funktions-Kommentare  
# Kurze DQN/Neural Network spezifische Beschreibung
def dqn_function(param1, param2):
    # DQN Implementation details
    pass

# Shared Funktions-Kommentare
# Beschreibung f√ºr beide Algorithmen verwendbare Funktion
def shared_function(param1, param2):
    # Implementation details f√ºr Q-Learning und DQN
    pass
```

### Versionskontrolle f√ºr Multi-Algorithmus Dokumentation
```bash
# Q-Learning spezifische Dokumentations-Updates
git add docs/
git commit -m "docs: Update Q-Learning training documentation"

# DQN spezifische Dokumentations-Updates
git commit -m "docs: Add DQN neural network architecture documentation"

# Algorithmus-Vergleich Updates
git commit -m "docs: Update Q-Learning vs DQN comparison analysis"

# Mit semantischen Commit-Messages
git commit -m "docs(setup): Add Q-Learning and DQN installation troubleshooting"
git commit -m "docs(training): Document Q-Learning vs DQN parameter differences"
git commit -m "docs(comparison): Add algorithmus performance benchmarks"
```

## Code-Qualit√§t und Standards

### Multi-Algorithmus Import-Konventionen
```python
# Standard-Imports (beide Algorithmen)
import sys
import os
import numpy as np

# Q-Learning spezifische Imports
from q_learning.utils import qlearning, evaluation
from q_learning.utils.visualization import create_q_learning_curve

# DQN spezifische Imports
from dqn.deep_q_agent import DeepQLearningAgent
from dqn.train import DQNTrainer
import torch
import torch.nn as nn

# Shared Imports (beide Algorithmen)
from shared.config import (ENV_MODE, EPISODES, DQN_EPISODES, 
                          get_algorithm_export_path)
from shared.envs import GridEnvironment, ContainerShipEnv

# Comparison Imports
from comparison.compare_algorithms import AlgorithmComparison
```

### Algorithmus-spezifische Dokumentations-Integration
- **Q-Learning Code-Beispiele**: Alle Q-Tabellen Code-Blocks sind getestet
- **DQN Code-Beispiele**: Alle Neural Network Code-Blocks sind PyTorch-kompatibel
- **Shared Parameter-Referenz**: Zentrale config.py wird in allen Algorithmus-Docs referenziert
- **Algorithmus-Pfad-Konsistenz**: Alle Pfadangaben entsprechen der neuen Multi-Algorithmus Struktur
- **Cross-References**: Links zwischen Q-Learning, DQN und Vergleichs-Dokumentation

## Wartung und Updates

### Regelm√§√üige Multi-Algorithmus Aufgaben
- **Q-Learning Code-Beispiele aktualisieren**: Bei √Ñnderungen an der Q-Tabellen API
- **DQN Code-Beispiele aktualisieren**: Bei √Ñnderungen an der Neural Network API
- **Algorithmus-Vergleich Screenshots erneuern**: Bei UI/Visualisierungs-√Ñnderungen
- **Performance-Metriken**: Bei Q-Learning oder DQN Optimierungen
- **Dependency-Updates**: requirements.txt f√ºr beide Algorithmen synchron halten

### Multi-Algorithmus Dokumentations-Metriken
- **Q-Learning Vollst√§ndigkeit**: Alle Q-Tabellen Features dokumentiert
- **DQN Vollst√§ndigkeit**: Alle Neural Network Features dokumentiert
- **Vergleichs-Vollst√§ndigkeit**: Alle Algorithmus-Vergleiche dokumentiert
- **Aktualit√§t**: Code-Beispiele funktionieren mit aktueller Version beider Algorithmen
- **Zug√§nglichkeit**: Q-Learning und DQN Nutzergruppen ber√ºcksichtigt
- **Konsistenz**: Einheitliche Formatierung f√ºr beide Algorithmen

## Integration mit der Multi-Algorithmus Projektentwicklung

### Continuous Documentation f√ºr beide Algorithmen
```bash
# Bei Q-Learning Feature-Updates
git add src/q_learning/ docs/
git commit -m "feat(qlearning): Add q-table inspection tool

- New Q-Learning inspect_q_tables.py script
- Interactive Q-table analysis options
- Updated Q-Learning documentation in visualisierung.md"

# Bei DQN Feature-Updates
git add src/dqn/ docs/
git commit -m "feat(dqn): Add neural network architecture visualization

- New DQN network visualization in deep_q_agent.py
- Experience replay analysis tools
- Updated DQN documentation in funktionsweise.md"

# Bei Algorithmus-Vergleich Updates
git add src/comparison/ docs/
git commit -m "feat(comparison): Add statistical significance testing

- New algorithmus performance significance tests
- Enhanced Q-Learning vs DQN comparison plots
- Updated comparison documentation in training.md"
```

### Multi-Algorithmus Release-Vorbereitung
1. **Q-Learning Dokumentation vollst√§ndig aktualisieren**
2. **DQN Dokumentation vollst√§ndig aktualisieren**
3. **Algorithmus-Vergleich Dokumentation vollst√§ndig aktualisieren**
4. **Q-Learning Code-Beispiele testen**
5. **DQN Code-Beispiele testen**
6. **Algorithmus-Screenshots/Diagramme erneuern**
7. **mkdocs build** ohne Errors f√ºr alle Algorithmus-Inhalte
8. **GitHub Pages deployment** mit vollst√§ndiger Multi-Algorithmus Dokumentation

## Algorithmus-spezifische Dokumentations-Standards

### Q-Learning Dokumentations-Richtlinien
- **Q-Tabellen Terminologie**: Konsistente Verwendung von "Q-Tabelle", "Q-Werte", "Q-Learning"
- **Tabellenbasierte Konzepte**: Explizite Erw√§hnung der Tabellenstruktur
- **Diskrete Zustandsr√§ume**: Fokus auf diskrete, kleine Problemr√§ume
- **Deterministische Konvergenz**: Betonung der garantierten Konvergenz-Eigenschaften

### DQN Dokumentations-Richtlinien
- **Neural Network Terminologie**: Konsistente Verwendung von "Neural Network", "Experience Replay", "Target Network"
- **Funktionsapproximation**: Explizite Erw√§hnung der Function Approximation
- **Skalierbare Zustandsr√§ume**: Fokus auf Skalierbarkeit und gr√∂√üere Problemr√§ume
- **Approximative Konvergenz**: Betonung der approximativen aber praktischen Konvergenz

### Vergleichs-Dokumentations-Richtlinien
- **Neutrale Algorithmus-Darstellung**: Keine Bevorzugung eines Algorithmus
- **Kontext-abh√§ngige Empfehlungen**: Wann Q-Learning vs. wann DQN verwenden
- **Quantitative Vergleiche**: Immer mit statistischen Kennzahlen untermauert
- **Faire Bewertung**: Gleiche Evaluation-Bedingungen f√ºr beide Algorithmen

## Erweiterte Multi-Algorithmus Features

### Algorithmus-spezifische Diagramme
```markdown
# Q-Learning spezifische Mermaid Diagramme
```mermaid
graph TD
    A[Q-Table] --> B[State-Action Lookup]
    B --> C[Epsilon-Greedy Selection]
    C --> D[Q-Value Update]
```

# DQN spezifische Mermaid Diagramme
```mermaid
graph TD
    A[Neural Network] --> B[Forward Pass]
    B --> C[Experience Replay]
    C --> D[Batch Training]
    D --> E[Target Network Update]
```
```

### Code-Tabs f√ºr Algorithmus-Vergleiche
```markdown
=== "Q-Learning"
    ```python
    # Q-Learning Training
    Q[state, action] += alpha * (reward + gamma * max(Q[next_state]) - Q[state, action])
    ```

=== "DQN"
    ```python
    # DQN Training
    target_q = reward + gamma * target_network(next_state).max()
    loss = F.mse_loss(q_network(state)[action], target_q)
    ```
```

Die Multi-Algorithmus Dokumentation ist integraler Bestandteil der Softwarequalit√§t und erm√∂glicht sowohl Q-Learning als auch DQN Nutzern den effizienten Einstieg sowie erfahrenen Entwicklern die optimale Nutzung beider Algorithmen mit direkten Vergleichsm√∂glichkeiten.